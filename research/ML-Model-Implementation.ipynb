{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import contractions\n",
    "import langid\n",
    "import spacy\n",
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "from spacy.language import Language\n",
    "from spacy_language_detection import LanguageDetector\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, hamming_loss,accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'simplified/train-00000-of-00001.parquet', 'validation': 'simplified/validation-00000-of-00001.parquet', 'test': 'simplified/test-00000-of-00001.parquet'}\n",
    "train_df = pd.read_parquet(\"hf://datasets/google-research-datasets/go_emotions/\" + splits[\"train\"])\n",
    "valid_df = pd.read_parquet(\"hf://datasets/google-research-datasets/go_emotions/\" + splits[\"validation\"])\n",
    "test_df = pd.read_parquet(\"hf://datasets/google-research-datasets/go_emotions/\" + splits[\"test\"])\n",
    "# train_df = pd.read_csv(\"/Users/sudeepmungara/Documents/Personal_Projects/NLP/data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i:emotions[i] for i in range(len(emotions))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in id2label:\n",
    "    train_df[id2label[i]] = train_df.labels.apply(lambda x: 1 if i in x else 0)\n",
    "    valid_df[id2label[i]] = valid_df.labels.apply(lambda x: 1 if i in x else 0)\n",
    "    test_df[id2label[i]] = test_df.labels.apply(lambda x: 1 if i in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demojize_text(text):\n",
    "    return emoji.demojize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    # Ensure the input is a string\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove specific patterns and unwanted characters\n",
    "    text = re.sub(r'\\:(.*?)\\:', '', text)\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    \n",
    "    # Remove HTML content\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # Remove HTML tags, newlines, and words with numbers\n",
    "    text = re.sub(r'<.*?>+', '', text)\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    # Remove all punctuation\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Removes everything except word characters and spaces\n",
    "    \n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text=[]\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "            \n",
    "    x=new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(df):\n",
    "    df['text'] = df['text'].apply(lambda x: contractions.fix(x))\n",
    "    df['text'] = df['text'].apply(lambda x: demojize_text(x))\n",
    "    # df['text'] = df['text'].apply(lambda x: clean_text(x))\n",
    "    df['text'] = df['text'].apply(lambda x: remove_stopwords(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = text_preprocessing(train_df)\n",
    "test_df = text_preprocessing(test_df)\n",
    "valid_df = text_preprocessing(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(ngram_range=(3,3))\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer([text], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :]  # [CLS] token as sentence embedding\n",
    "    return embeddings[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['embeddings'] = train_df['text'].apply(get_bert_embeddings)\n",
    "test_df['embeddings'] = test_df['text'].apply(get_bert_embeddings)\n",
    "valid_df['embeddings'] = valid_df['text'].apply(get_bert_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23600633,  0.26128465, -0.00110828, ...,  0.04515841,\n",
       "         0.3806575 ,  0.2508166 ],\n",
       "       [-0.15286319,  0.20315409,  0.10535079, ..., -0.55064994,\n",
       "         0.9888965 ,  0.0919748 ],\n",
       "       [-0.00429128,  0.28572923,  0.04581843, ..., -0.17329574,\n",
       "         0.1313872 ,  0.14194687],\n",
       "       ...,\n",
       "       [ 0.01718974, -0.2551513 , -0.27539182, ..., -0.37481186,\n",
       "         0.03428522,  0.33105877],\n",
       "       [-0.14047493, -0.30260164,  0.05103033, ..., -0.6276323 ,\n",
       "         0.30474293,  0.30814284],\n",
       "       [-0.09355879,  0.05430624,  0.2569471 , ..., -0.11302563,\n",
       "        -0.23879355,  0.42790604]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(train_df['embeddings'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[emotions].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.stack(train_df['embeddings'].values)\n",
    "y_train = train_df[emotions].values\n",
    "X_test = np.stack(test_df['embeddings'].values)\n",
    "y_test = test_df[emotions].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_classifier = xgb_clf = XGBClassifier(random_state=42)\n",
    "# LogisticRegression(max_iter=5000,class_weight='balanced')\n",
    "model = MultiOutputClassifier(base_classifier, n_jobs=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sudeepmungara/Documents/Personal_Projects/NLP/venv/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1 Score: 0.14626138379190903\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate F1 score for multi-label classification\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "print(\"Macro F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21319329279528285"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
